# -*- coding: utf-8 -*-
"""Orchid Identifier

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-aU1PXDluEm8nfaQr68BfqCm39KYxRbT

# **Download the dataset**
首先先下載需要用到的資料，解壓縮後資料夾內的結構如下  
Training data 769張  
Testing data 166張  
總共有23個label(23種野生蘭花)
```
MLHW7_dataset/
|----train
    |----0_001.jpg
    |----0_002.jpg
      ...
    |----1_069.jpg
      ...
|----test
    |----0_001.jpg
    |----0_002.jpg
    ...
|----label_versus_Orchid_name.xlsx
```
"""
!gdown --id 1NTLuuaM831zN6oL4a0EX4cjIephAEPIC --output "data.zip"

!unzip -q "data.zip"

"""# **Import Packages**"""

import os
import glob
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torch.utils.data as data
import torchvision.transforms as transforms
from torchvision import datasets
from torchvision.datasets import DatasetFolder
from torchvision.transforms import AutoAugmentPolicy
from torch import optim
from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import random
import tensorflow as tf
import csv
import pandas as pd

"""### 固定 random seed"""

def same_seeds(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
same_seeds(87)

"""# **Dataset, Data Loader, and Transforms**
Reference:  
https://blog.csdn.net/weixin_41469023/article/details/115375927  
https://www.itread01.com/content/1544541602.html 
"""

class Orchid(Dataset):
    def __init__(self, root, transform=None):
        self.transform = transform
        self.filenames = []
        filenames = glob.glob(os.path.join(root,'*'))
        for fn in filenames:
            if root == 'MLHW7_dataset/train/':
              i = fn[20:]
              if i[1] == '_':
                i = i[:1]
              elif i[2] == '_':
                i = i[:2]
              elif i[3] == '_':
                i = i[:3]
            if root == 'MLHW7_dataset/test/':
              i = fn[19:]
              if i[1] == '_':
                i = i[:1]
              elif i[2] == '_':
                i = i[:2]
              elif i[3] == '_':
                i = i[:3]
            i = int(i)
            self.filenames.append((fn,i))
        self.len = len(self.filenames)
    def __getitem__(self, index):
        image_fn, label = self.filenames[index]
        image = Image.open(image_fn)
        if self.transform is not None:
            image = self.transform(image)
        return image, label
    def __len__(self):
        return self.len

"""## Data Augmentation
對現有圖片進行平移、翻轉、旋轉、改變明度對比度等方式來增加資料集
"""

randomAugment = [transforms.ColorJitter(0.1, 0.1, 0.1), transforms.ColorJitter(0.2, 0.2, 0.2)]
autoAugment = [transforms.AutoAugment(policy=AutoAugmentPolicy.IMAGENET),
         transforms.AutoAugment(policy=AutoAugmentPolicy.CIFAR10),
         transforms.AutoAugment(policy=AutoAugmentPolicy.SVHN)]

train_tfm1 = transforms.Compose([
	transforms.Resize((1024, 1024)),
  transforms.RandomChoice(randomAugment),
  transforms.RandomHorizontalFlip(p=0.7),
	transforms.ToTensor(),
  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_tfm2 = transforms.Compose([
	transforms.Resize((1024, 1024)),
  transforms.RandomChoice(randomAugment),
  transforms.RandomHorizontalFlip(p=0.5),
  transforms.AutoAugment(policy=AutoAugmentPolicy.IMAGENET),
  transforms.RandomAffine(degrees=20, translate=(0.12, 0.12), scale=(0.8, 1.2)),
	transforms.ToTensor(),
  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_tfm3 = transforms.Compose([
	transforms.Resize((1024, 1024)),
  transforms.RandomChoice(randomAugment),
  transforms.RandomHorizontalFlip(p=0.7),
  transforms.AutoAugment(policy=AutoAugmentPolicy.CIFAR10),
  transforms.RandomAffine(degrees=30, translate=(0.12, 0.12), scale=(0.8, 1.2)),
	transforms.ToTensor(),
  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_tfm4 = transforms.Compose([
	transforms.Resize((1024, 1024)),
  transforms.RandomChoice(randomAugment),
  transforms.RandomHorizontalFlip(p=0.8),
  transforms.AutoAugment(policy=AutoAugmentPolicy.SVHN),
  transforms.RandomAffine(degrees=15, translate=(0.12, 0.12), scale=(0.8, 1.2)),
	transforms.ToTensor(),
  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_tfm5 = transforms.Compose([
	transforms.Resize((1024, 1024)),
  transforms.RandomChoice(randomAugment),
  transforms.ColorJitter(0.3, 0.2, 0.15),
  transforms.RandomHorizontalFlip(p=0.6),
  transforms.AutoAugment(policy=AutoAugmentPolicy.IMAGENET),
	transforms.ToTensor(),
  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

test_tfm = transforms.Compose([
    transforms.Resize((1024, 1024)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

"""## Load Data
把所有資料包裝好之後載下來
"""

# Construct datasets.
train_set1 = Orchid("MLHW7_dataset/train/", transform=train_tfm1)
train_set2 = Orchid("MLHW7_dataset/train/", transform=train_tfm2)
train_set3 = Orchid("MLHW7_dataset/train/", transform=train_tfm3)
train_set4 = Orchid("MLHW7_dataset/train/", transform=train_tfm4)
train_set5 = Orchid("MLHW7_dataset/train/", transform=train_tfm5)
train_set = ConcatDataset([train_set1, train_set2, train_set3, train_set4, train_set5])
validation_set = Orchid("MLHW7_dataset/test/", transform=test_tfm)

print('# images in trainset:', len(train_set)) 
print('# images in validationset:', len(validation_set))

# Construct data loaders.
batch_size = 4
train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)
valid_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)

# get some random training images
dataiter = iter(train_loader)
images, labels = dataiter.next()
print('Image tensor in each batch:', images.shape, images.dtype)
print('Label tensor in each batch:', labels.shape, labels.dtype)

"""看一下要train的圖片，確認做完data augmentation後的圖片合不合理"""

import matplotlib.pyplot as plt
import numpy as np

# functions to show an image
def imshow(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    
# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print('Labels:')
print(' '.join('%5s' % labels[j] for j in range(4)))

"""# **Model**"""

# 看一下哪一種GPU，不過現在免費版的只剩下超爛的K80
# 運氣好可以抽到Tesla T4
use_cuda = torch.cuda.is_available()
torch.manual_seed(87)
device = torch.device("cuda" if use_cuda else "cpu")
print('Device used:', device)
!nvidia-smi

import torchvision.models as models 
model = models.efficientnet_b2(pretrained=True).to(device)
model.classifier = nn.Sequential(
    nn.Dropout(p=0.3, inplace=True),
    nn.Linear(in_features=1408, out_features=23, bias=True),
    ).to(device)

print(model)

"""# **Training**"""

from tqdm.auto import tqdm

import torchvision.models as models

device = "cuda" if torch.cuda.is_available() else "cpu"
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)
n_epochs = 7
best_acc = 0
# checkpoint = torch.load('drive/MyDrive/model.pt')
# model.load_state_dict(checkpoint['model_state_dict'])
# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

for epoch in range(n_epochs):
    model.train()
    train_loss = []
    train_accs = []
    for batch in tqdm(train_loader):
        imgs, labels = batch
        logits = model(imgs.to(device))
        loss = criterion(logits, labels.to(device))
        optimizer.zero_grad()
        loss.backward()
        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)
        optimizer.step()
        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()
        train_loss.append(loss.item())
        train_accs.append(acc)
    train_loss = sum(train_loss) / len(train_loss)
    train_acc = sum(train_accs) / len(train_accs)
    print(f"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}")

    model.eval()
    valid_loss = []
    valid_accs = []
    for batch in tqdm(valid_loader):
        imgs, labels = batch
        with torch.no_grad():
          logits = model(imgs.to(device))
        loss = criterion(logits, labels.to(device))
        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()
        valid_loss.append(loss.item())
        valid_accs.append(acc)
    valid_loss = sum(valid_loss) / len(valid_loss)
    valid_acc = sum(valid_accs) / len(valid_accs)
    print(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}")
    if valid_acc > best_acc:
        best_acc = valid_acc
        torch.save({
          'optimizer_state_dict': optimizer.state_dict(),
          'model_state_dict': model.state_dict(),
          'loss': loss
          },'model.pt')
        print('model saved')

"""# **Prediction**"""

model.eval()
label_list = []
filename_list = []
path = 'MLHW7_dataset/test/'

for infile in glob.glob(os.path.join(path,'*')):
  infile2 = infile[19:]
  infile2 = infile2[:-8]
  filename_list.append(infile[19:])
  label_list.append(infile2)
print(filename_list)
print(label_list)

predictions = []
for batch in tqdm(valid_loader):
    imgs, labels = batch
    with torch.no_grad():
        logits = model(imgs.to(device))
    predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())

with open("Orchid_prediction.csv", "w") as f:
    f.write("Filename,True_label,Predicted_label\n")
    for i, pred in  enumerate(predictions):
         f.write(f"{filename_list[i]},{label_list[i]},{pred}\n")
        #  f.write(f"{i},{pred}\n")

from google.colab import files
files.download("Orchid_prediction.csv")
files.download("model.pt")